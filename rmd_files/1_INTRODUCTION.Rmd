---
output:
  html_document: default
  pdf_document: default
---
Muchos arqueólogos están familiarizados con las estadísticas bayesianas en el contexto de la calibración de fechas por radiocarbono y la construcción de cronologías. Sin embargo, el marco bayesiano tiene aplicaciones más amplias más allá de la datación y la cronología que merecen ser consideradas por los arqueólogos. Por ejemplo, muchos investigadores de las ciencias naturales y sociales utilizan las estadísticas bayesianas para evaluar qué tan bien se alinean los datos observacionales o experimentales con sus hipótesis. En su mayor parte, este uso de la inferencia bayesiana no se ha aplicado a la arqueología. Utilizando un ejemplo zooarqueológico ficticio, este documento proporciona una explicación directa de la inferencia bayesiana y la compara con la prueba de significación de hipótesis nula (NHST) más convencional. Aunque algunos han descrito y revisado previamente la aplicación de estos conceptos en otros lugares [por ejemplo @buck_bayesian_1996;@buck_applications_2001;@buck_being_2015;@otarola-castillo_bayesian_2018;@otarola-castillo_bayesian_2022;@wolfhagen_rethinking_2019;@wolfhagen_re-examining_2020], este trabajo está centrado en presentar ejemplos reproducibles paso a paso del marco bayesiano con la finalidad de evaluar y discernir entre hipótesis contrapuestas.


### Incertidumbre y probabilidad en aplicaciones arqueológicas

Todos los datos son inciertos. Las mediciones y observaciones no son exactas y sus valores resultantes son variablemente imprecisos. Los arqueólogos suelen utilizar cantidades estadísticas como la varianza, la desviación estándar y el error estándar, que están basados en la teoría de la probabilidad para describir esta incertidumbre. En su trabajo de campo y laboratorio, los arqueólogos emplean regularmente equipos basados en descripciones probabilísticas de incertidumbre. Por ejemplo, el fabricante de estaciones totales, ampliamente utilizadas para mapear sitios arqueológicos, ha establecido precisiones de 2 mm más 2 mm adicionales por km, generalmente en el nivel de desviación estándar de 1 sigma (por ejemplo, Leica TS16). Este es un ejemplo de un concepto de probabilidad utilizado para medir la incertidumbre «aleatoria». En este caso, suponiendo una distribución de probabilidad «normal» para el error de medición (aunque el fabricante no lo especifica), los arqueólogos deben esperar que el 68 % de las ubicaciones de los artefactos cartografiados por este instrumento tengan un error de hasta ± 2 mm, más el error relacionado con el incremento de la distancia (y el error debido a las condiciones atmosféricas, la estabilidad del instrumento, etc.  [@walker_total_2020]). De forma similar, la hoja de especificaciones del fabricante para una báscula digital portátil típica de Ohaus (Scout STX2202) afirma medir hasta 2200 g, con un error de ± 0.02 g (1 sigma). Al igual que las estaciones totales, si asumimos un modelo de error normal, esto quiere decir que el fabricante certifica que el 68 % de todas las lecturas estarán dentro de ±0.02 g de la lectura real en circunstancias ideales. 
 De forma similar, después de una cuidadosa recopilación y análisis de datos, los arqueólogos también aplican el concepto de probabilidad para probar sus hipótesis. Estas son declaraciones formales que ofrecen explicaciones plausibles de los patrones observados de las personas o su entorno en el pasado. Al igual que las afirmaciones sobre las mediciones de instrumentos de campo y laboratorio, estas hipótesis y sus predicciones también poseen cierto grado de incertidumbre debido a la observación o conocimiento incompletos. Para cuantificar de manera formal la incertidumbre sobre los datos y las hipótesis, los arqueólogos suelen confiar en modelos de probabilidad específicos o funciones de probabilidad (es decir, ecuaciones). Las entradas de una función de probabilidad son valores observados o hipotéticos, y los resultados son sus probabilidades que van de cero a uno, es decir, de menos probable a más probable. son sus probabilidades que van de cero a uno, es decir, de menos probable a más probable. Los arqueólogos utilizan este sistema probabilístico para probar sus hipótesis y describir el grado de incertidumbre con el que sus hipótesis dan cuenta de las observaciones actuales y futuras probables. El uso de un planteamiento probabilístico ofrece a los arqueólogos una herramienta poderosa y sistemática que posibilita la interpretación datos y evaluación de hipótesis.
A continuación, proporcionamos una descripción general de los conceptos centrales de los dos principales paradigmas de probabilidad para evaluar hipótesis: NHST e inferencia bayesiana. Mientras que la mayoría de los científicos utilizan ampliamente NHST, el planteamiento bayesiano se considera un moderno sistema de aprendizaje basado en datos que ha gozado de una aplicación cada vez mayor en la arqueología [@jaynes_probability_2003;@howson_scientific_2006;@buck_bayesian_1996,@buck_being_2015;@otarola-castillo_differentiating_2018;@otarola-castillo_bayesian_2022]

### Prueba de significación de la hipótesis nula

Como marco estadístico prevaleciente en la mayoría de las ciencias, NHST permite a los profesionales utilizar sus datos para evaluar hipótesis. Este planteamiento tiene sus raíces en el desarrollo a principios del siglo XX de las pruebas de bondad de ajuste [@fisher_interpretation_1922;@pearson_x_1900], el diseño experimental, los valores de p [@fisher_statistical_1925;@fisher_design_1935], los intervalos de confianza (IC) y las pruebas de hipótesis [@neyman_problem_1933,p.294]. Esta metodología se introdujo en la arqueología a mediados del siglo XX [por ejemplo, @binford_consideration_1964;@clarke_analytical_1968;@myers_applications_1950;@spaulding_statistical_1953;@vescelius_archaeological_1960]. Las aplicaciones de NHST en arqueología continúan hoy, respaldadas por nuevos libros de texto estadísticos específicos de arqueología [por ejemplo, @banning_archaeologists_2020;@baxter_statistics_2003;@carlson_quantitative_2017;@drennan_statistics_2010;@fletcher_digging_2005;@mccall_strategies_2018;@shennan_quantifying_1997].Estos libros de texto brindan un tratamiento detallado de NHST y sus procedimientos en el contexto de la arqueología (para un libro de texto de introducción multidisciplinario a NHST, consulte, por ejemplo, [@diez_openintro_2019]).

Sin embargo, en general, el paradigma NHST gira en torno al concepto de muestreo repetido teóricamente a largo plazo y el Teorema central del límite (TCL; @diez_openintro_2019[p.172]). El TCL informa el planteamiento del NHST para la descripción y evaluación de hipótesis. El teorema muestra que dada una muestra lo suficientemente grande, en muchos casos, las estadísticas de resumen (por ejemplo, media o desviación estándar) seguirán una distribución normal. Por ejemplo, después de muestrear la misma población varias veces, las medias de las muestras individuales se distribuirán normalmente. Esta distribución se conoce como muestreo o distribución «nula» de la estadística. Como este fenómeno ocurre frecuentemente, incluso si la variable original no tenía una distribución normal, este concepto se aplica a muchas situaciones y datos. El TCL vincula además las estadísticas de muestra con sus distribuciones nulas, como la media, a través de su error estándar. Según la TCL, el error estándar de la media de una muestra estima la desviación estándar de la distribución nula de la media. Esta cantidad puede calcularse dividiendo la desviación estándar de la muestra por el tamaño de la muestra.

El TCL es útil para los arqueólogos que a menudo toman muestras de una población objetivo: un grupo de individuos, artefactos, eventos, mediciones u otros fenómenos que desean estudiar. El objetivo es usar la muestra para probar hipótesis a priori sobre características cuantificables de la población muestreada. Los estadísticos se refieren a estas características como los parámetros de la población. Por ejemplo, los parámetros de media y desviación estándar de una población representan su tendencia central y variabilidad, respectivamente. Las estadísticas de muestra funcionan como estimaciones de los parámetros de la población y, por lo tanto, también se conocen como estimaciones de parámetros. Estas estadísticas se usar con la finalidad de probar hipótesis sobre sus respectivos parámetros de población. NHST requiere que los arqueólogos establezcan únicamente dos hipótesis: una hipótesis nula y una alternativa a evaluar. Las hipótesis nulas son afirmaciones cuantitativas de «ninguna diferencia» (diferencia = 0) entre un valor de parámetro hipotético y su estadística de muestra, o entre una estadística de muestra y su contraparte de otra muestra. Los arqueólogos a menudo establecen tales hipótesis nulas para evaluar si una muestra estadística resultó de una población que tiene el valor del parámetro hipotético (es decir, una prueba de una muestra). Alternativamente, pueden desear saber si las estadísticas de dos muestras independientes se extrajeron de la misma población (es decir, una prueba de dos muestras).
Las hipótesis alternativas son declaraciones ordinariamente simples que niegan la hipótesis nula. Una vez que los arqueólogos establecen las hipótesis nula y alternativa, toman muestras de la población o «recolectan datos» y calculan las estadísticas de la muestra. Tenemos que señalar que el marco NHST procede asumiendo que la hipótesis nula es verdadera y posteriormente utiliza los datos de la muestra, resumidos por una estadística, para probar esa suposición. Para hacerlo, los arqueólogos utilizan la estadística de muestra para definir una estadística de prueba (con frecuencia, los valores z-, t-, ratios F- y los valores de chi-cuadrado; por ejemplo, @diez_openintro_2019;@thomas_reconfiguring_1986; @drennan_statistics_2010[p.177]) y calculan la probabilidad de que un valor igual o más extremo que el estadístico de prueba pueda ocurrir bajo el supuesto de la hipótesis nula.
La probabilidad de la estadística de prueba, o valor p, a menudo se calcula con la ayuda de modelos de distribución de probabilidad, como la distribución normal. Estos modelos de probabilidad son conocidos también como funciones de verosimilitud. La verosimilitud es una función estadística que describe la probabilidad de la estadística de prueba que depende de los valores de los parámetros hipotéticos, por ejemplo, los asumidos por la hipótesis nula. Por ejemplo, como mostramos en el ejemplo ficticio a continuación, la función de verosimilitud normal es utilizada para calcular el valor p de una estadística de prueba de ratio z, suponiendo que la hipótesis nula es verdadera. Utilizando modelos de probabilidad similares, los arqueólogos realizan NHST y calculan cantidades tales como valores p e intervalos de confianza (IC) para evaluar si la estadística de prueba rechaza o no rechaza la hipótesis nula.
Los IC están basados en el concepto de distribución nula de TCL. Los arqueólogos a menudo calculan los IC en dos contextos: 1) para realizar NHST, calculan los IC de una estadística de prueba, y 2) para estimar la precisión de la estimación de un parámetro, calculan los IC de una estadística de muestra. En general, los IC de la estadística de prueba o de muestra se centran en su media, representan su distribución nula respectiva y se derivan usando el error estándar de su muestra. Recuerde que el error estándar de cualquier estadística es la desviación estándar de su distribución nula. Para la estadística muestral, esta distribución representa el rango de valores plausibles dentro de los cuales puede encontrarse el verdadero valor de los parámetros de la población.
Sin embargo, en el contexto de la estadística de prueba, el IC es el rango de valores posibles dentro del cual se encontrará la verdadera diferencia, asumida por la hipótesis nula. Dicho de otro modo, debido al TCL, ~68 % de la distribución nula de la estadística de prueba capturará el verdadero valor de la diferencia, que la hipótesis nula supone que es cero. Asimismo, en el caso de un estadístico muestral, el 68 % de su distribución nula contendrá el verdadero valor del parámetro poblacional. Alternativamente, se puede desear una incertidumbre inferior al 68 % para la muestra o la estadística de prueba. En este caso, pueden calcularse rangos similares al error estándar que capturan el parámetro real o los valores de diferencia entre el 95 % y el 99 % de las veces, nuevamente, después de un muestreo teórico repetido. Estos rangos son los IC, y nos referimos a ellos en términos de su porcentaje: por ejemplo, como 95 % o 99 % IC. En el contexto de NHST, los arqueólogos usan los IC de la estadística de prueba para rechazar o no una hipótesis nula. Si el valor de ninguna diferencia, 0, está dentro del IC de la estadística de prueba, entonces la hipótesis nula no se rechaza. Sin embargo, si 0 no está dentro del rango de IC de la estadística de prueba, los datos no respaldan la hipótesis nula y se rechaza a favor de la alternativa. Ofrecemos una última nota sobre la mecánica de los IC. Puede parecer tentador interpretar el IC del 95 % como una indicación de que el verdadero parámetro o diferencia de la población tiene una probabilidad de 0.95 de estar en el IC. Aunque algo confuso, sin embargo, la interpretación correcta del IC es que, con base en un muestreo repetido a largo plazo, el 95 % de los IC contendrá el verdadero parámetro o diferencia de la población. 

Además de los IC, NHST utiliza valores p como una señal empírica de la plausibilidad de la estadística de prueba, asumiendo que la hipótesis nula es verdadera. Los arqueólogos calculan los valores p calculando la proporción de valores en la distribución nula igual y más extrema que el estadístico de prueba de la muestra. Por lo general, los valores estadísticos de prueba con un valor p menor o igual a una proporción de 0.05 (1 de 20 o 5 %) son considerados extremos. Es común que los arqueólogos juzguen si rechazar o no la hipótesis nula utilizando un valor p de 0.05 como límite para el rechazo: cuanto más extremos son los datos, menor es el valor p.

La comunidad científica en general se ha vuelto cada vez más crítica con el NHST [por ejemplo: @gelman_failure_2018;@gelman_multilevel_2006;@vidgen_p-values_2016]. Los estadísticos han señalado enérgicamente la arbitrariedad del umbral del valor p de 0.05 para la significación estadística [@cowgill_trouble_1977;@valeggia_moving_2022; @Wasserstein_movingbeyond_2019].Algunos argumentan que una formación estadística no adecuada puede llevar a los investigadores a malinterpretar los valores p [@hubbard_widespread_2011;@mcshane_blinding_2015]. Una consecuencia de no comprender completamente el concepto de valores p, por ejemplo, es que algunos investigadores confunden el significado práctico, o relevancia, con el significado estadístico. En particular, es posible que los efectos que son prácticamente insignificantes, irrelevantes o poco interesantes den como resultado valores p pequeños [por ejemplo, @aarts_insignificance_2012;@johnson_insignificance_1999;@kramer_sibling_2016;@mccall_strategies_2018;@wolverton_practical_2016]. En un caso, mientras investigaban los efectos de la competencia entre hermanos en los patrones de crecimiento de los niños mayas, Kramer et al. [-@kramer_sibling_2016] encontró que los efectos del tamaño de la familia en el crecimiento de los niños eran estadísticamente significativos, pero «de poca importancia para la salud o el estado físico de la primera infancia». Aquí, interpretar el límite del valor p de 0.05 como demográficamente importante habría llevado a conclusiones incorrectas.
En otros casos, los investigadores han confundido los valores p con la tasa de error de tipo I, α. El valor p es la probabilidad de que la estadística de prueba pueda ocurrir bajo la hipótesis nula; α es la probabilidad de rechazar la hipótesis nula cuando es verdadera [@hubbard_widespread_2011]. Históricamente, estas dos cantidades estadísticas pertenecen a filosofías NHST en competencia [@fisher_statistical_1925;@neyman_problem_1933]. Neyman y Pearson desarrollaron el concepto de error tipo 1 en el contexto del diseño de experimentos infinitamente repetibles, donde α define la probabilidad de que un análisis no encuentre una diferencia entre dos hipótesis cuando hay una diferencia genuina. Contrariamente, el valor p de Fisher, estima empíricamente si un conjunto específico de observaciones se ajusta a una hipótesis nula específica. Estas dos cantidades tienen fundamentos teóricos y relaciones completamente distintas con las observaciones reales. Por ejemplo, α no está relacionado con las observaciones y el valor p no está influenciado por las hipótesis alternativas bajo consideración. Desafortunadamente, la práctica típica de NHST puede llevar a los investigadores a asociar directamente los dos conceptos, complicando los esfuerzos para proporcionar definiciones e interpretaciones razonables [@hubbard_confusion_2003]. El mal uso de los valores de p y la significación estadística, debido a un malentendid [por ejemplo, @thiese_misuse_2015] o intención [@chuard_evidence_2019;@head_extent_2015], puede dar lugar a la llamada crisis de replicación científic [@ioannidis_why_2005], que empieza a alcanzar a la ciencia arqueológica [@bayliss_confessions_2019;@marwick_computational_2017;@mcpherron_machine_2021-3] 

Incluso teniendo en cuenta estos matices, la interpretación de los conceptos del NHST, como los valores p, la significación estadística, las pruebas de hipótesis y los IC, no es del todo sencilla. Las declaraciones sobre las estadísticas de la muestra (errores estándar e IC) están basados en un muestreo repetido hipotético, que es difícil de concebir en situaciones no experimentales o, como en arqueología, donde la replicación real es difícil o incluso imposible de lograr. En términos de evaluación, aunque la mayoría de los investigadores en general pueden entender cómo interpretar un valor p significativo en el contexto de rechazar una hipótesis nula, el significado de un valor p no significativo puede causar confusión. Esta confusión podría verse exacerbada por el hecho de que no existe un mecanismo para «aceptar» o «verificar» una hipótesis nula. Este malentendido crítico del NHST puede llevar a algunos a interpretar un valor p no significativo como una aceptación de su hipótesis nula en vez de rechazarla [@greenland_statistical_2016]. Sin embargo, la producción de conocimiento en el paradigma NHST se centra en rechazar las hipótesis nulas, en vez de aceptar las hipótesis nulas o alternativas. Para ser justos, el lenguaje del NHST es confuso. Por ejemplo, afirmar que una hipótesis nula no pudo ser rechazada es un triple negativo, lo que significa que «la hipótesis de no diferencia no fue no aceptada». Tal lenguaje intrincado incluido en NHST ofusca la relación entre las hipótesis de valor p, nula y alternativa.
Además, el papel de la hipótesis alternativa y su conexión con el valor p tampoco están claros y, a menudo, se interpretan incorrectamente [@cohen_earth_1994;@benjamin_three_2019]. Como resultado, la inferencia utilizando estadísticas NHST tradicionales puede ser difícil, especialmente cuando un estudio desea discernir entre múltiples hipótesis de trabajo [ por ejemplo, @chamberlin_method_1965;@gelman_why_2012], por ejemplo, cuando dos o más hipótesis no logran ser rechazadas. En teoría, tales hipótesis son consistentes con los datos. Sin embargo, clasificar múltiples hipótesis nulas no rechazadas es difícil, si no imposible. Una forma de clasificarlos puede ser utilizar los valores p de las hipótesis. Después de todo, el valor p es una métrica continua que media el rechazo de hipótesis y la falta de rechazo. Sin embargo, los estadísticos desaconsejan este procedimiento [@hubbard_why_2008;@mcshane_abandon_2019] porque la magnitud del valor p no refleja el peso de la evidencia de una hipótesis sobre otra. En consecuencia, el NHST tradicional no ofrece un procedimiento sencillo para comparar más hipótesis nulas «no rechazadas». 

### Estadísticas bayesianas

La inferencia bayesiana ofrece un planteamiento alternativo con varias ventajas sobre NHST. En primer lugar, las estadísticas bayesianas permiten a los científicos utilizar datos para asignar probabilidades a las estimaciones de sus parámetros e hipótesis, lo que facilita una comparación más directa de las hipótesis contrapuestas. En segundo lugar, mientras que el NHST utiliza solamente datos nuevos para hacer inferencias, un marco bayesiano permite combinar tanto datos nuevos como información existente. Como detallamos a continuación, esta característica se parece más a los procesos de toma de decisiones de los científicos y es probablemente una de las razones clave por las que los científicos, incluidos los antropólogos y arqueólogos, están adoptando cada vez más la inferencia bayesiana para evaluar sus hipótesis. 

El teorema de Bayes deriva su nombre del reverendo Thomas Bayes
 [-@bayes_essay_1763], un ministro presbiteriano inglés y matemático que investigó problemas de probabilidad que involucraban probabilidades condicionales y previas (definidas a continuación). Sin embargo, no fue hasta finales de 1900 que el planteamiento bayesiano de la inferencia estadística se popularizó en la ciencia [@bellhouse_reverend_2004].Aunque los arqueólogos comenzaron notablemente a adoptar estadísticas bayesianas para evaluar hipótesis en la década de 1990 [por ejemplo, @buck_bayesian_1996;@cowgill_distinguished_1993], pueden encontrarse aplicaciones anteriores dispersas en la literatura arqueológica a partir de la década de 1970 [@doran_mathematics_1975;@fisher_mastodont_1987;@freeman_bayesian_1976;@thomas_reconfiguring_1986;@salmon_philosophy_1982]. Hoy en día, los científicos, incluidos los antropólogos y arqueólogos que encuentran ventajoso este planteamiento, están aplicando cada vez más las estadísticas bayesianas para evaluar sus hipótesis con datos [@gelman_bayesian_2020;@mcelreath_statistical_2020;@naylor_archaeological_1988;@otarola-castillo_bayesian_2018]. 

Una ventaja de la inferencia bayesiana es que permite incorporar información previa o experta sobre hipótesis en los análisis estadísticos. Como mostramos en nuestro ejemplo a continuación, el conocimiento previo de un arqueólogo o un conjunto de arqueólogos y otros expertos puede ser muy valioso ya que «dependemos mucho de la información previa para ayudarnos a evaluar el grado de plausibilidad en un nuevo problema» [@jaynes_probability_2003,p.6]. Incluir formalmente experiencia previa o información de expertos en análisis estadísticos para «actualizar» el estado de conocimiento de uno es un proceso de aprendizaje natural y mejora las inferencias hechas por NHST [@cowgill_past_2001]. Para lograr esto, los practicantes de la inferencia bayesiana convierten el conocimiento previo en probabilidades previas y las utilizan junto con sus distribuciones como parte de los análisis estadísticos. Una vez que los analistas determinan sus distribuciones de probabilidad previas, como con el NHST, pueden observar nuevos datos para probar su hipótesi (o hipótesis). En este contexto, la verosimilitud de los datos se combina con (o se pondera por) la previa para dar la probabilidad posterior bayesiana. La posterior es la probabilidad de la hipótesis dada la verosimilitud de los datos observados y el conocimiento previo [@buck_bayesian_1996]. Como comentamos más detalladamente a continuación, el proceso bayesiano es particularmente útil en situaciones en las que solamente se obtienen pequeñas cantidades de datos, como suele ser el caso en arqueología.

En casos simples, determinar el posterior y su distribución es relativamente sencillo. Sin embargo, el cálculo subyacente a casos más complejos es imposible de resolver sin la aplicación de nuevos métodos de simulación. En particular, los algoritmos Markov Chain Monte Carlo (MCMC) han facilitado el progreso en los análisis bayesianos. La simulación MCMC es una combinación de muestreo de Monte Carlo y cadenas de Markov. El muestreo de Monte Carlo se utiliza para estimar cantidades difíciles de calcular a partir de la distribución desconocida de una variable aleatoria observada. Las cadenas de Markov son una serie estocástica de eventos asociados entre sí, donde la probabilidad de un nuevo evento depende únicamente del estado del último evento. Juntas, estas características del muestreo de Monte Carlo y las cadenas de Markov son esenciales para encontrar la distribución de probabilidad posterior de problemas complejos. Hoy en día, las variaciones del algoritmo MCMC original [@metropolis_equation_1953], como Metropolis-Hastings, Gibbs, hamiltoniano y otros métodos, ahora se utilizan ampliamente, lo que facilita una amplia aplicación del paradigma bayesiano [por ejemplo, @dunson_hastings_2020;@gilks_markov_1995;@howson_scientific_2006;@robert_short_2011]. 

Para contextualizar todavía más la aplicación de las estadísticas bayesianas, proporcionamos un ejemplo ficticio que ilustra cómo puede utilizarse este marco probabilístico para resolver un problema de investigación arqueológica idealizado. Para hacer esto, elegimos usar una parábola^[Este ejemplo se inspiró en obras creativas similares a Neil Thompson’s (1972) The Mysterious Fall of the Nacirema, Kent Flannery’s The Early Mesoamerican Village (1976) y The Golden Marshalltown (1982), y John Shea’s Uwasi Valley Tales de «Prehistoric Stone Tools of Eastern Africa: A Guide» (2020).] en vez de un estudio de caso real para evitar las complejidades de los procesos de formación de sitios y el sesgo de muestreo. El ejemplo inventado y ficticio de esta parábola también ayuda a centrar la atención en aspectos específicos de la inferencia bayesiana, que creemos que son muy instructivos. La parábola de la «Cultura de Monico y el arqueólogo bayesiano» demuestra cómo se pueden hacer inferencias utilizando datos e información previa sobre una hipótesis, cómo evaluar la incertidumbre que rodea a una hipótesis, por qué este plantenamiento parece menos ambiguo que el NHST y, por lo tanto, por qué se está volviendo cada vez más popular.